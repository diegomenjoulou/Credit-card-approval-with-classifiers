{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card application study\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "    <br /> \n",
    "For the past 10 years I worked at a Bank where one of my duties was credit analysis and approval. Back in 2010 we did them manually on an excel spreadsheet and with the documentation printed out. In the last few years we implemented a software based on rules that discarded or approved the credit application, but it always seemed to me that it was an inflexible model, and the features were taken into account individually and not in a combined way. So I came across this dataset from the UCI Machine Learning Repository about credit cards approvals and tried to implement a ML model to see if it can be predicted accurately.\n",
    "    <br /> \n",
    "<br /> \n",
    "Although te column names are available, the data was anonymized to protect the privacy.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/cc_approvals.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender    Age   Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "0      b  30.83  0.000       u            g              w         v   \n",
       "1      a  58.67  4.460       u            g              q         h   \n",
       "2      a  24.50  0.500       u            g              q         h   \n",
       "3      b  27.83  1.540       u            g              w         v   \n",
       "4      b  20.17  5.625       u            g              w         v   \n",
       "\n",
       "  YearsEmployed PriorDefault Employed CreditScore DriversLicense Citizen  \\\n",
       "0          1.25            t        t           1              f       g   \n",
       "1          3.04            t        t           6              f       g   \n",
       "2          1.50            t        f           0              f       g   \n",
       "3          3.75            t        t           5              t       g   \n",
       "4          1.71            t        f           0              f       s   \n",
       "\n",
       "  ZipCode Income ApprovalStatus  \n",
       "0   00202      0              +  \n",
       "1   00043    560              +  \n",
       "2   00280    824              +  \n",
       "3   00100      3              +  \n",
       "4   00120      0              +  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [['Gender',\n",
    "               'Age',\n",
    "               'Debt',\n",
    "               'Married',\n",
    "               'BankCustomer',\n",
    "               'EducationLevel',\n",
    "               'Ethnicity',\n",
    "               'YearsEmployed',\n",
    "               'PriorDefault',\n",
    "               'Employed',\n",
    "               'CreditScore',\n",
    "               'DriversLicense',\n",
    "               'Citizen',\n",
    "               'ZipCode',\n",
    "               'Income',\n",
    "               'ApprovalStatus']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# There is almost 5% of missing categorical data, as it isn't significant we impute the mean\n",
    "df = df.replace('?', np.NaN)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# For the numeric missing values we impute the most frequent value\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == 'object':\n",
    "        df = df.fillna(df[col].value_counts)\n",
    "\n",
    "assert df.isna().sum().sum(axis = 0, skipna = False) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pre-procesisng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Use LabelEncoder to transform labels to numeric\n",
    "le = LabelEncoder()\n",
    "for col in df.columns.values:\n",
    "    if df[col].dtypes =='object':\n",
    "        df[col]=le.fit_transform(df[col].astype(str))  \n",
    "\n",
    "# Drop non relevant features\n",
    "df = df.drop(['DriversLicense', 'ZipCode','Ethnicity'], axis=1)\n",
    "\n",
    "X = df.iloc[:, 0:-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "def print_performance(model):\n",
    "    ''' Takes a classification model executed \n",
    "    and returns accuracy and confusion matrix'''\n",
    "    pd.options.display.float_format = '{:,.0f}'.format\n",
    "    print('Accuracy: ', '{:,.3f}'.format(model.score(X_test, y_test)))\n",
    "    print('\\n','Confusion Matrix: ')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.838\n",
      "\n",
      " Confusion Matrix: \n",
      "[[92 11]\n",
      " [26 99]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit and predict\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print_performance(log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.855\n",
      "\n",
      " Confusion Matrix: \n",
      "[[ 91  12]\n",
      " [ 21 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "r_forest = RandomForestClassifier(random_state=np.random.seed(5))\n",
    "\n",
    "# Fit and predict\n",
    "r_forest.fit(X_train, y_train)\n",
    "y_pred = r_forest.predict(X_test)\n",
    "\n",
    "print_performance(r_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.855\n",
      "\n",
      " Confusion Matrix: \n",
      "[[ 89  14]\n",
      " [ 19 106]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgboost = xgboost.XGBClassifier()\n",
    "\n",
    "# Fit and predict\n",
    "xgboost.fit(X_train, y_train)\n",
    "y_pred = xgboost.predict(X_test)\n",
    "\n",
    "print_performance(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "As it is a credit card approval, the highest risk is in the customers that shouldn't get a credit card but they obtain it. Those are the false positives. So even though the RandomForest and XGB preformed the same in accuracy, the count of false positives is less in the RandomForest. We will try to improve Random Forest accuracy by tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter tunning on Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 125}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8608695652173913"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': np.arange(50,151,25),\n",
    "              'max_depth': [2,3,4],\n",
    "              'min_samples_leaf': [1,2],\n",
    "              'min_samples_split':[2,3,4,5]\n",
    "}\n",
    "\n",
    "r_forest_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv=4) \n",
    "r_forest_cv.fit(X, y)\n",
    "\n",
    "print(r_forest_cv.best_params_)\n",
    "r_forest_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the sample is small we managed to improve the accuracy by tuning hyperparameters. The best fit of the 3 is the Random Forest and it would be nice to try it with a bigger sample vs the XGboost to check if this persists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cc_approval_r_forest.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Fit the best params to the final model\n",
    "r_forest = RandomForestClassifier()\n",
    "r_forest.set_params(**r_forest_cv.best_params_)\n",
    "r_forest.fit(X, y)\n",
    "\n",
    "# Persist the final model\n",
    "dump(r_forest, 'cc_approval_r_forest.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

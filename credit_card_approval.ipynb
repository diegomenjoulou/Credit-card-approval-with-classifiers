{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card application study\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "    <br /> \n",
    "For the past 10 years I worked at a Bank where one of my duties was credit analysis and approval. Back in 2010 we did them manually on an excel spreadsheet and with the documentation printed out. In the last few years we implemented a software based on rules that discarded or approved the credit application, but it allways seemed to me that it was an inflexible model, and the features were taken into account individually and not in a combiened way. So I came across this dataset from the UCI Machine Learning Repository about credit cards approvals and tried to implement a ML model to see if it can be predicted accurately.\n",
    "    <br /> \n",
    "<br /> \n",
    "Altough te column names are available, the data was anonymized to protect the privacy.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/cc_approvals.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender    Age   Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "0      b  30.83  0.000       u            g              w         v   \n",
       "1      a  58.67  4.460       u            g              q         h   \n",
       "2      a  24.50  0.500       u            g              q         h   \n",
       "3      b  27.83  1.540       u            g              w         v   \n",
       "4      b  20.17  5.625       u            g              w         v   \n",
       "\n",
       "  YearsEmployed PriorDefault Employed CreditScore DriversLicense Citizen  \\\n",
       "0          1.25            t        t           1              f       g   \n",
       "1          3.04            t        t           6              f       g   \n",
       "2          1.50            t        f           0              f       g   \n",
       "3          3.75            t        t           5              t       g   \n",
       "4          1.71            t        f           0              f       s   \n",
       "\n",
       "  ZipCode Income ApprovalStatus  \n",
       "0   00202      0              +  \n",
       "1   00043    560              +  \n",
       "2   00280    824              +  \n",
       "3   00100      3              +  \n",
       "4   00120      0              +  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [['Gender',\n",
    "               'Age',\n",
    "               'Debt',\n",
    "               'Married',\n",
    "               'BankCustomer',\n",
    "               'EducationLevel',\n",
    "               'Ethnicity',\n",
    "               'YearsEmployed',\n",
    "               'PriorDefault',\n",
    "               'Employed',\n",
    "               'CreditScore',\n",
    "               'DriversLicense',\n",
    "               'Citizen',\n",
    "               'ZipCode',\n",
    "               'Income',\n",
    "               'ApprovalStatus']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect label example : ?\n",
      "\n",
      "Count of NaNs:\n",
      "Gender            12\n",
      "Age               12\n",
      "Debt               0\n",
      "Married            6\n",
      "BankCustomer       6\n",
      "EducationLevel     9\n",
      "Ethnicity          9\n",
      "YearsEmployed      0\n",
      "PriorDefault       0\n",
      "Employed           0\n",
      "CreditScore        0\n",
      "DriversLicense     0\n",
      "Citizen            0\n",
      "ZipCode           13\n",
      "Income             0\n",
      "ApprovalStatus     0\n",
      "dtype: int64\n",
      "\n",
      "Count of NaNs after mean imputation:\n",
      "Gender            0\n",
      "Age               0\n",
      "Debt              0\n",
      "Married           0\n",
      "BankCustomer      0\n",
      "EducationLevel    0\n",
      "Ethnicity         0\n",
      "YearsEmployed     0\n",
      "PriorDefault      0\n",
      "Employed          0\n",
      "CreditScore       0\n",
      "DriversLicense    0\n",
      "Citizen           0\n",
      "ZipCode           0\n",
      "Income            0\n",
      "ApprovalStatus    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# There is some values incorrectly labeled, for example:\n",
    "print('incorrect label example : '+ df.iloc[673][0])\n",
    "\n",
    "# Replace the '?'s with NaN\n",
    "df = df.replace('?', np.NaN)\n",
    "\n",
    "# There is almost 5% of missing data, as it isn't much we imputate the mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Count the number of NaNs in the dataset to verify\n",
    "print('')\n",
    "print('Count of NaNs:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "for col in df.columns:\n",
    "    # Check if the column is of object type\n",
    "    if df[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        df = df.fillna(df[col].value_counts)\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "print('')\n",
    "print('Count of NaNs after mean imputation:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-procesisng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Use LabelEncoder to transform labels to numeric\n",
    "le = LabelEncoder()\n",
    "for col in df.columns.values:\n",
    "    if df[col].dtypes =='object':\n",
    "        df[col]=le.fit_transform(df[col].astype(str))  \n",
    "\n",
    "# Drop the features Driving License and ZipCode and convert the DataFrame to a NumPy array\n",
    "df = df.drop(['DriversLicense', 'ZipCode'], axis=1)\n",
    "#df = df.values\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "#X,y = df[:,0:13].values , df[:,13].values\n",
    "X = df.iloc[:, 0:13].values\n",
    "y = df.iloc[:, 13].values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)\n",
    "\n",
    "def results(model):\n",
    "    ''' Takes a clasiffication model executed \n",
    "    and returns accuracy and confusion matrix'''\n",
    "    pd.options.display.float_format = '{:,.0f}'.format\n",
    "    print('Accuracy: ', '{:,.2f}'.format(model.score(rescaledX_test, y_test)))\n",
    "    print('')\n",
    "    print('Confusion Matrix: ')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84\n",
      "\n",
      "Confusion Matrix: \n",
      "[[92 11]\n",
      " [26 99]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression(random_state=seed)\n",
    "\n",
    "# Fit to the train set and meassure\n",
    "logreg.fit(rescaledX_train, y_train)\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Results\n",
    "results(logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.76\n",
      "\n",
      "Confusion Matrix: \n",
      "[[92 11]\n",
      " [44 81]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate a Random Forest classifier with default parameter values\n",
    "rforest = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# Fit to the train set and meassure\n",
    "rforest.fit(rescaledX_train, y_train)\n",
    "y_pred = rforest.predict(rescaledX_test)\n",
    "\n",
    "# Results\n",
    "results(rforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 89  14]\n",
      " [ 22 103]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "# Instantiate a XGBoost classifier with default parameter values\n",
    "xgboost = xgboost.XGBClassifier(random_state=seed)\n",
    "\n",
    "# Fit to the train set and meassure\n",
    "xgboost.fit(rescaledX_train, y_train)\n",
    "y_pred = xgboost.predict(rescaledX_test)\n",
    "\n",
    "# Results\n",
    "results(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "As it is a credit card approval, the highest risk is in the customers that shouldn't get a credit card but they obtain it. Those are the false positives. So even though the LogReg and XGB preformed the same in accuracy, the count of false positives is less in the LogReg.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tunning on selected model (LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 40, 'tol': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8478260869565217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "param_grid = {'tol': [0.01, 0.001, 0.0001, 0.00001],\n",
    "              'max_iter': np.arange(0,151,20)}\n",
    "\n",
    "# Iter over parameters with a cross validation of 5\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5) \n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Return best parameters\n",
    "print(logreg_cv.best_params_)\n",
    "logreg_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cc_approval_logreg.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Fit the best params\n",
    "logreg = LogisticRegression()\n",
    "logreg.set_params(**logreg_cv.best_params_)\n",
    "\n",
    "# Fit to the train set and meassure\n",
    "logreg.fit(rescaledX_train, y_train)\n",
    "\n",
    "dump(logreg, 'cc_approval_logreg.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
